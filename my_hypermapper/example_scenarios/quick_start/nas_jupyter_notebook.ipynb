{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a notebook wherefrom I can work on my NAS problem for HyperMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "from torch.autograd import Variable\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translates HyperMapper json to pyTorch module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class json2pheno(nn.Module):\n",
    "    def __init__(self, json, nin, nout):\n",
    "        super(json2pheno, self).__init__()\n",
    "        # build layers from genome encoding\n",
    "\n",
    "        n_in = nin\n",
    "        fw_map = {}\n",
    "\n",
    "        # stupid loop but I want to know how deep the net will be\n",
    "        active_list = []\n",
    "        for param in json.keys():\n",
    "            if param[:-2] == 'active' and json[param] == 1:\n",
    "                active_list.append(param[-1])\n",
    "\n",
    "        # Add the active layers in the encoding to the model\n",
    "        for new_i, old_i in enumerate(active_list):\n",
    "            key = str(new_i)\n",
    "            setattr(self, key, nn.Linear(n_in, json['n_nodes']))\n",
    "\n",
    "            # We are on the last hidden layer, so we will not have any skipps here\n",
    "            if new_i == len(active_list) - 1:\n",
    "                fw_map[key] = ['out']\n",
    "                # at current setting n_in is same for all but first layer\n",
    "                n_in = json['n_nodes']\n",
    "                break\n",
    "\n",
    "            fw_map[key] = [str(new_i + 1)]\n",
    "\n",
    "            # Add skips to the fw_map. If they are to long, sent them to output layer\n",
    "            if 'skip_' + str(old_i) in json:\n",
    "                target = json['skip_' + str(old_i)] + new_i + 1\n",
    "                if target >= len(active_list):\n",
    "                    fw_map[key].append('out')\n",
    "                elif target > new_i + 1:\n",
    "                    fw_map[key].append(str(target))\n",
    "\n",
    "            # Again, this is same for all but first layer\n",
    "            n_in = json['n_nodes']\n",
    "\n",
    "        setattr(self, 'out', nn.Linear(n_in, nout))\n",
    "\n",
    "        # fw_scheme is a dict containing to which layers each layer is sending its output\n",
    "        # This will fail if we have non-forward connections\n",
    "        self.fw_scheme = fw_map\n",
    "        print(self.fw_scheme)\n",
    "\n",
    "    def forward(self, x):\n",
    "        k = 0\n",
    "        X = dict()\n",
    "        X[str(k)] = [x]\n",
    "        while hasattr(self, str(k)):\n",
    "            # pass trough all layers except the output layer\n",
    "            key = str(k)\n",
    "\n",
    "            # we might want to concat instead of sum, then we need to modify input_size in __init__\n",
    "            temp_x = sum(X[key])\n",
    "            temp_out = torch.tanh(getattr(self, key)(temp_x))\n",
    "            # this seem to work when doing the list thing with x\n",
    "            for target in self.fw_scheme[key]:\n",
    "                if target in X:\n",
    "                    X[target].append(temp_out)\n",
    "                else:\n",
    "                    X[target] = [temp_out]\n",
    "\n",
    "            k += 1\n",
    "\n",
    "        # if k = 0 we have no active layers and a perceptron model\n",
    "        if k:\n",
    "            temp_x = sum(X['out'])\n",
    "        else:\n",
    "            temp_x = x\n",
    "\n",
    "        # Identity as output function since we do regression\n",
    "        # Add support for other types od problems problems\n",
    "        out = getattr(self, 'out')(temp_x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takes network and trains it for given number of epochs given a objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stole most of this online, should be improved uppon\n",
    "# Maybe let it be and do a proper fuction when doing the mnist problem\n",
    "def trainer(net, epochs, noise, objective='x2'):\n",
    "    torch.manual_seed(1)  # reproducible\n",
    "\n",
    "    x = torch.unsqueeze(torch.linspace(-1, 1, 20), dim=1)  # x data (tensor), shape=(100, 1)\n",
    "\n",
    "    if objective == 'x2':\n",
    "        y = x.pow(2) + noise * torch.rand(x.size())  # noisy y data (tensor), shape=(100, 1)\n",
    "    elif objective == 'sinx':\n",
    "        y = torch.sin(3 * 3.14 * x) + noise * torch.rand(x.size())  # noisy y data (tensor), shape=(100, 1)\n",
    "\n",
    "    # torch can only train on Variable, so convert them to Variable\n",
    "    x, y = Variable(x), Variable(y)\n",
    "    # does this help me??\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "    print(net)  # net architecture\n",
    "\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.2)\n",
    "    loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
    "\n",
    "    # train the network\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    for t in range(epochs):\n",
    "        prediction = net(x)  # input x and predict based on x\n",
    "        loss = loss_func(prediction, y)  # must be (1. nn output, 2. target)\n",
    "\n",
    "        optimizer.zero_grad()  # clear gradients for next train\n",
    "        loss.backward()  # backpropagation, compute gradients\n",
    "        optimizer.step()  # apply gradients\n",
    "\n",
    "    loss = loss.data.numpy()\n",
    "    tr_time = time.perf_counter() - t0\n",
    "    # print(tr_time, \"seconds to train\")\n",
    "\n",
    "    # view data\n",
    "    #plt.figure(figsize=(10, 4))\n",
    "    #plt.scatter(x.data.numpy(), y.data.numpy(), color=\"orange\")\n",
    "    #plt.plot(x.data.numpy(), prediction.data.numpy(), 'g-', lw=3)\n",
    "\n",
    "    #plt.title('Regression Analysis')\n",
    "    #plt.text(1.0, 0, 'Loss = %.4f' % loss,\n",
    "             #fontdict={'size': 24, 'color': 'red'})\n",
    "    #plt.show()\n",
    "\n",
    "    return loss, tr_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Used in the HyperMapper solver. Takes a json scenario and returns a score based on the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NAS_function(X):\n",
    "    \"\"\"\n",
    "    Compute the branin function.\n",
    "    :param X: dictionary containing the input points.\n",
    "    :return: the value of the branin function\n",
    "    \"\"\"\n",
    "    nin = 1\n",
    "    nout = 1\n",
    "\n",
    "    eps = 2000    # 5000\n",
    "    noise = 0.3\n",
    "    my_net = json2pheno(X, nin, nout)\n",
    "\n",
    "    loss, t = trainer(my_net, eps, noise, objective='sinx')\n",
    "    score = loss * t\n",
    "    # do not consider time for now\n",
    "    print(100 * loss)\n",
    "    return 100 * loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makes the json scenario for the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/samuel\n",
      "/home/samuel/PycharmProjects/hypermapper/example_scenarios/quick_start\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "scenario = {}\n",
    "scenario[\"application_name\"] = \"nas\"\n",
    "scenario[\"optimization_objectives\"] = [\"Value\"]\n",
    "scenario[\"optimization_iterations\"] = 5\n",
    "scenario[\"input_parameters\"] = {}\n",
    "\n",
    "n_nodes = {}\n",
    "n_nodes[\"parameter_type\"] = \"ordinal\"\n",
    "n_nodes[\"values\"] = [2**i for i in range(2, int(math.log(16, 2)) + 1)]\n",
    "\n",
    "#n_lay = {}\n",
    "#n_lay[\"parameter_type\"] = \"integer\"\n",
    "#n_lay[\"values\"] = [1, 5]\n",
    "\n",
    "active_0 = {}\n",
    "active_0[\"parameter_type\"] = \"ordinal\"\n",
    "active_0[\"values\"] = [0, 1]\n",
    "\n",
    "skip_0 = {}\n",
    "skip_0[\"parameter_type\"] = \"integer\"\n",
    "skip_0[\"values\"] = [0, 4]\n",
    "\n",
    "active_1 = {}\n",
    "active_1[\"parameter_type\"] = \"ordinal\"\n",
    "active_1[\"values\"] = [0, 1]\n",
    "\n",
    "skip_1 = {}\n",
    "skip_1[\"parameter_type\"] = \"integer\"\n",
    "skip_1[\"values\"] = [0, 4]\n",
    "\n",
    "active_2 = {}\n",
    "active_2[\"parameter_type\"] = \"ordinal\"\n",
    "active_2[\"values\"] = [0, 1]\n",
    "\n",
    "skip_2 = {}\n",
    "skip_2[\"parameter_type\"] = \"integer\"\n",
    "skip_2[\"values\"] = [0, 4]\n",
    "\n",
    "active_3 = {}\n",
    "active_3[\"parameter_type\"] = \"integer\"\n",
    "active_3[\"values\"] = [0, 1]\n",
    "\n",
    "skip_3 = {}\n",
    "skip_3[\"parameter_type\"] = \"integer\"\n",
    "skip_3[\"values\"] = [0, 4]\n",
    "\n",
    "\n",
    "scenario[\"input_parameters\"][\"n_nodes\"] = n_nodes\n",
    "#scenario[\"input_parameters\"][\"n_lay\"] = n_lay\n",
    "scenario[\"input_parameters\"][\"active_0\"] = active_0\n",
    "scenario[\"input_parameters\"][\"skip_0\"] = skip_0\n",
    "scenario[\"input_parameters\"][\"active_1\"] = active_1\n",
    "#scenario[\"input_parameters\"][\"skip_1\"] = skip_1\n",
    "scenario[\"input_parameters\"][\"active_2\"] = active_2\n",
    "#scenario[\"input_parameters\"][\"skip_2\"] = skip_2\n",
    "#scenario[\"input_parameters\"][\"active_3\"] = active_3\n",
    "#scenario[\"input_parameters\"][\"skip_3\"] = skip_3\n",
    "%cd\n",
    "%cd \"PycharmProjects/hypermapper/example_scenarios/quick_start\"\n",
    "with open(\"example_nas_scenario.json\", \"w\") as scenario_file:\n",
    "    json.dump(scenario, scenario_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basically the main method. Optimizes the given function based on the given scenario. \n",
    "\n",
    "## Stores the results in nas_output_samples.cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/samuel\n",
      "/home/samuel/PycharmProjects/hypermapper/scripts\n",
      "/home/samuel/PycharmProjects/hypermapper\n",
      "Design of experiment phase, number of doe samples = 10 .......\n",
      "{'0': ['1', 'out'], '1': ['2'], '2': ['out']}\n",
      "json2pheno(\n",
      "  (0): Linear(in_features=1, out_features=8, bias=True)\n",
      "  (1): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (2): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (out): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "8.850663900375366\n",
      "{'0': ['1', 'out'], '1': ['out']}\n",
      "json2pheno(\n",
      "  (0): Linear(in_features=1, out_features=4, bias=True)\n",
      "  (1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (out): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "36.808255314826965\n",
      "{'0': ['out']}\n",
      "json2pheno(\n",
      "  (0): Linear(in_features=1, out_features=4, bias=True)\n",
      "  (out): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "47.031956911087036\n",
      "{}\n",
      "json2pheno(\n",
      "  (out): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "47.1607506275177\n",
      "{'0': ['out']}\n",
      "json2pheno(\n",
      "  (0): Linear(in_features=1, out_features=8, bias=True)\n",
      "  (out): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "46.380311250686646\n",
      "{'0': ['1'], '1': ['out']}\n",
      "json2pheno(\n",
      "  (0): Linear(in_features=1, out_features=4, bias=True)\n",
      "  (1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (out): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "34.21598970890045\n",
      "{'0': ['1', '2'], '1': ['2'], '2': ['out']}\n",
      "json2pheno(\n",
      "  (0): Linear(in_features=1, out_features=4, bias=True)\n",
      "  (1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (out): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "28.365713357925415\n",
      "{'0': ['1'], '1': ['out']}\n",
      "json2pheno(\n",
      "  (0): Linear(in_features=1, out_features=8, bias=True)\n",
      "  (1): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (out): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "33.83634686470032\n",
      "{'0': ['out']}\n",
      "json2pheno(\n",
      "  (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n",
      "44.77176070213318\n",
      "{'0': ['out']}\n",
      "json2pheno(\n",
      "  (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n",
      "44.77176070213318\n",
      "n_nodes,active_0,skip_0,active_1,active_2,Value,Timestamp\n",
      "8,1,2,1,1,8.850663900375366,9465\n",
      "4,1,1,1,0,36.808255314826965,17162\n",
      "4,0,0,0,1,47.031956911087036,22638\n",
      "8,0,3,0,0,47.1607506275177,25252\n",
      "8,0,1,1,0,46.380311250686646,30560\n",
      "4,1,0,0,1,34.21598970890045,38337\n",
      "4,1,1,1,1,28.365713357925415,49143\n",
      "8,0,3,1,1,33.83634686470032,56925\n",
      "16,0,3,1,0,44.77176070213318,62217\n",
      "16,0,3,0,1,44.77176070213318,67513\n",
      "\n",
      "\n",
      "End of doe phase, the number of new configuration runs is: 10\n",
      "\n",
      "Starting optimization iteration 1\n",
      "{'0': ['1', 'out'], '1': ['2'], '2': ['out']}\n",
      "json2pheno(\n",
      "  (0): Linear(in_features=1, out_features=4, bias=True)\n",
      "  (1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (out): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "47.15118408203125\n",
      "n_nodes,active_0,skip_0,active_1,active_2,Value,Timestamp\n",
      "4,1,2,1,1,47.15118408203125,77754\n",
      "\n",
      "Starting optimization iteration 2\n",
      "{'0': ['1', 'out'], '1': ['2'], '2': ['out']}\n",
      "json2pheno(\n",
      "  (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "  (1): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n",
      "17.349515855312347\n",
      "n_nodes,active_0,skip_0,active_1,active_2,Value,Timestamp\n",
      "16,1,2,1,1,17.349515855312347,89045\n",
      "\n",
      "Starting optimization iteration 3\n",
      "{'0': ['1'], '1': ['2'], '2': ['out']}\n",
      "json2pheno(\n",
      "  (0): Linear(in_features=1, out_features=8, bias=True)\n",
      "  (1): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (2): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (out): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "31.75879716873169\n",
      "n_nodes,active_0,skip_0,active_1,active_2,Value,Timestamp\n",
      "8,1,0,1,1,31.75879716873169,98918\n",
      "\n",
      "Starting optimization iteration 4\n",
      "{'0': ['1', 'out'], '1': ['2'], '2': ['out']}\n",
      "json2pheno(\n",
      "  (0): Linear(in_features=1, out_features=8, bias=True)\n",
      "  (1): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (2): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (out): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "45.42942941188812\n",
      "n_nodes,active_0,skip_0,active_1,active_2,Value,Timestamp\n",
      "8,1,3,1,1,45.42942941188812,109537\n",
      "\n",
      "Starting optimization iteration 5\n",
      "{'0': ['1', 'out'], '1': ['out']}\n",
      "json2pheno(\n",
      "  (0): Linear(in_features=1, out_features=8, bias=True)\n",
      "  (1): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (out): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "35.68255305290222\n",
      "n_nodes,active_0,skip_0,active_1,active_2,Value,Timestamp\n",
      "8,1,2,0,1,35.68255305290222,118274\n",
      "\n",
      "End of Random Scalarizations\n",
      "### End of the hypermapper script.\n"
     ]
    }
   ],
   "source": [
    "%cd\n",
    "%cd \"PycharmProjects/hypermapper/scripts\"\n",
    "#import sys\n",
    "# sys.path.append('../../scripts')\n",
    "#sys.path.append('scripts')\n",
    "import hypermapper\n",
    "%cd \"..\"\n",
    "\n",
    "parameters_file = \"example_scenarios/quick_start/example_nas_scenario.json\"\n",
    "# parameters_file = \"example_branin_scenario.json\"\n",
    "hypermapper.optimize(parameters_file, NAS_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branin_output_samples.csv  hypermapper_logfile.log  README.md  visualize.py\r\n",
      "\u001b[0m\u001b[01;34mexample_outputs\u001b[0m/           LICENSE                  \u001b[01;34mscripts\u001b[0m/\r\n",
      "\u001b[01;34mexample_scenarios\u001b[0m/         nas_output_samples.csv   \u001b[01;34mtests\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
