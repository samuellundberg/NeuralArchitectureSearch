{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make HyperMapper solve Mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, yay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "\n",
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.utils.data as Data\n",
    "\n",
    "#tds\n",
    "import torchvision\n",
    "\n",
    "#git\n",
    "#from __future__ import print_function\n",
    "#import argparse\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads the MNIST data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "      torchvision.datasets.MNIST('data/', train=True, \n",
    "                                  download=True,\n",
    "                                  transform=torchvision.transforms.Compose([\n",
    "                                   torchvision.transforms.ToTensor(),\n",
    "                                   torchvision.transforms.Normalize(\n",
    "                                     (0.1307,), (0.3081,))\n",
    "                                 ])),\n",
    "                                  batch_size = 64, \n",
    "                                    shuffle=True)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "      torchvision.datasets.MNIST('data/', train=False, download=True,\n",
    "                                 transform=torchvision.transforms.Compose([\n",
    "                                   torchvision.transforms.ToTensor(),\n",
    "                                   torchvision.transforms.Normalize(\n",
    "                                     (0.1307,), (0.3081,))\n",
    "                                 ])),\n",
    "                                  batch_size = 1000, shuffle=True)\n",
    "    print('loaded the mnist data')\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translates HyperMapper json to pyTorch module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in the nas notebook\n",
    "class json2pheno(nn.Module):\n",
    "    def __init__(self, json, nin, nout):\n",
    "        super(json2pheno, self).__init__()\n",
    "        # build layers from genome encoding\n",
    "\n",
    "        n_in = nin\n",
    "        fw_map = {}\n",
    "\n",
    "        \"\"\"vad jag har i json:\n",
    "        n_nodes\n",
    "        n_layers (räknar alla utom output)\n",
    "        skip (hur långa skips vi gör, kan vara 0)\n",
    "        \"\"\" \n",
    "        n_nodes = json['n_nodes']\n",
    "        n_layers = json['n_layers']\n",
    "        skip = json['skip']\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            key = str(i)\n",
    "            setattr(self, key, nn.Linear(n_in, n_nodes))\n",
    "           \n",
    "            # We are on the last hidden layer, so we will not have any skipps here\n",
    "            if i == n_layers - 1:\n",
    "                fw_map[key] = ['out']\n",
    "                n_in = n_nodes\n",
    "                break\n",
    "            \n",
    "            fw_map[key] = [str(i + 1)]\n",
    "            \n",
    "            # Add skips to the fw_map. If they are to long, sent them to output layer\n",
    "            if skip:\n",
    "                if i + skip + 1 < n_layers:\n",
    "                    fw_map[key].append(str(i + skip + 1))\n",
    "                else:\n",
    "                    fw_map[key].append('out')\n",
    "\n",
    "            \n",
    "            # Again, this is same for all but first layer\n",
    "            n_in = n_nodes\n",
    "\n",
    "        setattr(self, 'out', nn.Linear(n_in, nout))\n",
    "\n",
    "        # fw_scheme is a dict containing to which layers each layer is sending its output\n",
    "        # This will fail if we have non-forward connections\n",
    "        self.fw_scheme = fw_map\n",
    "        print(self.fw_scheme)\n",
    "\n",
    "    def forward(self, x):\n",
    "        k = 0\n",
    "        X = dict()\n",
    "        X['0'] = [x.view(x.shape[0],-1)]\n",
    "        while hasattr(self, str(k)):\n",
    "            # pass trough all layers except the output layer\n",
    "            key = str(k)\n",
    "\n",
    "            # we might want to concat instead of sum, then we need to modify input_size in __init__\n",
    "            temp_x = sum(X[key])\n",
    "            temp_out = torch.tanh(getattr(self, key)(temp_x))\n",
    "            # this seem to work when doing the list thing with x\n",
    "            for target in self.fw_scheme[key]:\n",
    "                if target in X:\n",
    "                    X[target].append(temp_out)\n",
    "                else:\n",
    "                    X[target] = [temp_out]\n",
    "\n",
    "            k += 1\n",
    "\n",
    "        # if k = 0 we have no active layers and a perceptron model\n",
    "        if k:\n",
    "            temp_x = sum(X['out'])\n",
    "        else:\n",
    "            temp_x = x.view(x.shape[0],-1)\n",
    "\n",
    "        # Identity as output function since we do regression\n",
    "        # Add support for other types od problems problems\n",
    "        out = getattr(self, 'out')(temp_x)\n",
    "        return F.log_softmax(out, dim = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a json scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scenario(doe, BO=0, output_path = \"output_samples.csv\"):\n",
    "    scenario = {}\n",
    "    scenario[\"application_name\"] = \"mnist\"\n",
    "    scenario[\"optimization_objectives\"] = [\"Value\"]\n",
    "    scenario[\"input_parameters\"] = {}\n",
    "    scenario[\"output_data_file\"] = output_path\n",
    "    scenario[\"design_of_experiment\"] = {}\n",
    "\n",
    "    # doe: nbr of random samples\n",
    "    # BO: nbr op BO iters. BO = 0 means only random sampling\n",
    "    scenario[\"optimization_iterations\"] = BO\n",
    "    scenario[\"design_of_experiment\"][\"doe_type\"] = \"random sampling\"\n",
    "    scenario[\"design_of_experiment\"][\"number_of_samples\"] = doe\n",
    "\n",
    "\n",
    "    n_nodes = {}\n",
    "    n_nodes[\"parameter_type\"] = \"ordinal\"\n",
    "    n_nodes[\"values\"] = [2**i for i in range(2, int(math.log(128, 2)) + 1)] # 16-128\n",
    "\n",
    "    n_layers = {}\n",
    "    n_layers[\"parameter_type\"] = \"integer\"\n",
    "    n_layers[\"values\"] = [0, 2]\n",
    "\n",
    "    skip = {}\n",
    "    skip[\"parameter_type\"] = \"integer\"\n",
    "    skip[\"values\"] = [0, 1]\n",
    "\n",
    "    scenario[\"input_parameters\"][\"n_nodes\"] = n_nodes\n",
    "    scenario[\"input_parameters\"][\"n_layers\"] = n_layers\n",
    "    scenario[\"input_parameters\"][\"skip\"] = skip\n",
    "\n",
    "    %cd\n",
    "    %cd \"PycharmProjects/samuel_nas/my_hypermapper/example_scenarios/quick_start\"\n",
    "    with open(\"example_mnist_scenario.json\", \"w\") as scenario_file:\n",
    "        json.dump(scenario, scenario_file, indent=4)\n",
    "\n",
    "    n_nodes[\"values\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trains a network and returns validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(network, train_data, test_data):\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(network.parameters(), lr=0.1)\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    for epoch in range(4):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_data, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            #running_loss += loss.item()\n",
    "            #if i % 200 == 199:    # print every 200 mini-batches\n",
    "             #   print('[%d, %5d] loss: %.3f' %\n",
    "              #        (epoch + 1, i + 1, running_loss / 200))\n",
    "               # running_loss = 0.0\n",
    "\n",
    "    print('Finished Training it took ', (time.perf_counter() - t0)/60, ' minutes to train')\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_data:\n",
    "            images, labels = data\n",
    "            outputs = network(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    #print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "     #   100 * correct / total))\n",
    "    # return error rate \n",
    "    return 1 - correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective function for hypermapper to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNIST_function(X):\n",
    "    \"\"\"\n",
    "    Compute the branin function.\n",
    "    :param X: dictionary containing the input points.\n",
    "    :return: the value of the branin function\n",
    "    \"\"\"\n",
    "    # do not load each time\n",
    "    train_loader, test_loader = get_mnist()\n",
    "\n",
    "    nin = 28**2\n",
    "    nout = 10\n",
    "\n",
    "    my_net = json2pheno(X, nin, nout)\n",
    "\n",
    "    loss = trainer(my_net, train_loader, test_loader)\n",
    "    print(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basically the main method. Optimizes the given function based on the given scenario. \n",
    "\n",
    "### Stores the results in nas_output_samples.cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/samuel\n",
      "/home/samuel/PycharmProjects/samuel_nas/my_hypermapper/example_scenarios/quick_start\n",
      "/home/samuel\n",
      "/home/samuel/PycharmProjects/samuel_nas/my_hypermapper/scripts\n",
      "/home/samuel/PycharmProjects/samuel_nas/my_hypermapper\n",
      "\n",
      " ####\n",
      " Warning: reached maximum number of Random sampling that have been already run. \n",
      "The Random sampling configuration selection will stop now. Is the search space very small?\n",
      "\n",
      "Design of experiment phase, number of doe samples = 30 .......\n",
      "loaded the mnist data\n",
      "{}\n",
      "Finished Training it took  0.9766110861998943  minutes to train\n",
      "0.10199999999999998\n",
      "loaded the mnist data\n",
      "{}\n",
      "Finished Training it took  0.965285011450275  minutes to train\n",
      "0.13\n",
      "loaded the mnist data\n",
      "{'0': ['out']}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f2ee9e6c9ff7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# parameters_file = \"example_branin_scenario.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mt_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mhypermapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMNIST_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'this entire procedure took '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_start\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'minutes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/samuel_nas/my_hypermapper/scripts/hypermapper.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(parameters_file, black_box_function)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptimization_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"random_scalarizations\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mrandom_scalarizations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblack_box_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblack_box_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0moptimization_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"local_search\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mlocal_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblack_box_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblack_box_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/samuel_nas/my_hypermapper/scripts/random_scalarizations.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config, black_box_function, output_file)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                                 \u001b[0mexhaustive_search_data_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                                 \u001b[0mexhaustive_search_fast_addressing_of_data_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m                                                 run_directory)\n\u001b[0m\u001b[1;32m    667\u001b[0m     \u001b[0mabsolute_configuration_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnumber_of_doe_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0menable_feasible_predictor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/samuel_nas/my_hypermapper/scripts/space.py\u001b[0m in \u001b[0;36mrun_configurations\u001b[0;34m(self, hypermapper_mode, configurations, beginning_of_time, black_box_function, exhaustive_search_data_array, exhaustive_search_fast_addressing_of_data_array, run_directory, number_of_cpus)\u001b[0m\n\u001b[1;32m   1547\u001b[0m                                                                         \u001b[0mconfigurations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1548\u001b[0m                                                                         \u001b[0mblack_box_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1549\u001b[0;31m                                                                         beginning_of_time)\n\u001b[0m\u001b[1;32m   1550\u001b[0m             \u001b[0mprint_data_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhypermapper_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exhaustive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/samuel_nas/my_hypermapper/scripts/space.py\u001b[0m in \u001b[0;36mrun_configurations_with_black_box_function\u001b[0;34m(self, configurations, black_box_function, beginning_of_time)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                 \u001b[0mnew_data_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m             \u001b[0mobjective_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblack_box_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m             \u001b[0moutput_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-c9fdb7872a01>\u001b[0m in \u001b[0;36mMNIST_function\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmy_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson2pheno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-238b09ee2941>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(network, train_data, test_data)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;31m# PIL image mode: L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'YCbCr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fails to do many random samples. increase problem complexity\n",
    "doe = 30\n",
    "bo = 0\n",
    "op = \"mnist_RS_30.csv\"\n",
    "create_scenario(doe, BO=bo, output_path = op)\n",
    "\n",
    "%cd\n",
    "%cd \"PycharmProjects/samuel_nas/my_hypermapper/scripts\"\n",
    "\n",
    "import hypermapper\n",
    "%cd \"..\"\n",
    "parameters_file = \"example_scenarios/quick_start/example_mnist_scenario.json\"\n",
    "# parameters_file = \"example_branin_scenario.json\"\n",
    "t_start = time.perf_counter()\n",
    "hypermapper.optimize(parameters_file, MNIST_function)\n",
    "print('this entire procedure took ', (time.perf_counter() - t_start) / 60, 'minutes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv ('mnist_BO_10+20.csv')   \n",
    "data2 = pd.read_csv ('mnist_RS_30.csv')   \n",
    "\n",
    "scores = np.zeros((len(data),2))\n",
    "scores2 = np.zeros((len(data2),2))\n",
    "scores[0, :] = [0, data['Value'].iloc[0]]\n",
    "scores2[0, :] = [0, data2['Value'].iloc[0]]\n",
    "\n",
    "for i in range(1, len(data)):\n",
    "    scores[i, :] = [i, min(data['Value'].iloc[0:i])]\n",
    "    if i < len(data2):\n",
    "        scores2[i, :] = [i, min(data2['Value'].iloc[0:i])]\n",
    "    \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# view data\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.scatter(scores[:,0], scores[:,1], color = \"orange\")\n",
    "#plt.scatter(scores2[:,0], scores2[:,1], color = \"blue\")\n",
    "#plt.plot(x.data.numpy(), prediction.data.numpy(), 'g-', lw=3)\n",
    "plt.suptitle('Performance of the best found archtectiure as a function of samples. We trained on MNIST for 4 epochs')\n",
    "plt.xlabel('samples')\n",
    "plt.ylabel('fraction wrongly classified in validation set')\n",
    "#plt.title('Regression Analysis')\n",
    "#plt.text(1.0, 0, 'Loss = %.4f' % loss,\n",
    "            #fontdict={'size': 24, 'color':  'red'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
