{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "import time\n",
    "\n",
    "#tds\n",
    "import torchvision\n",
    "\n",
    "#git\n",
    "#from __future__ import print_function\n",
    "#import argparse\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(train_batch_size, test_batch_size, size=(32,32)):\n",
    "    # Cifar10 normalization: Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    \n",
    "    data_transform = Compose([ Resize(size) ,ToTensor(), Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "    train_loader = DataLoader(CIFAR10('data/', download=True, transform=data_transform, train=True),\n",
    "                              batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    test_loader = DataLoader(CIFAR10('data/', download=True, transform=data_transform, train=False),\n",
    "                            batch_size=test_batch_size, shuffle=False, num_workers=2)\n",
    "   \n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    print('loaded the mnist data')\n",
    "    return train_loader, test_loader, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts trainable weights in a model\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base for ResNet\n",
    "# Vill ha bilder av storlek 224x224\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "    # dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        \"\"\"\n",
    "        planes is the number of filters we want\n",
    "        inplanes can differ from planes as we can get inputs from multiple places\n",
    "        \"\"\"\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        groups=1,\n",
    "        base_width=64\n",
    "        dilation = 1\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11175370"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ResNet(nn.Module):\n",
    "    # ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "        self.inplanes = 64\n",
    "        \n",
    "        self.groups = 1\n",
    "        self.base_width = 64\n",
    "        # Första filtret för ResNet \"börjar\"\n",
    "        self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # ResNet\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        \n",
    "        # Slutfas\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "        # What is this???\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "        # might want to Zero-initialize the last BN in each residual branch here\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = 1\n",
    "        dilate=False\n",
    "        \n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion  # block expansion = 1 for basic block\n",
    "        \n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        # We do not need softmax since it is done inside nn.CrossEntropyLoss()\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "#ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "#print(ResNet(BasicBlock, [1,1,1,1]))\n",
    "\n",
    "count_params(ResNet(BasicBlock, [2,2,2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init:  layer1\n",
      "init:  layer2\n",
      "init:  layer3\n",
      "init:  layer4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4888930"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class myResNet(nn.Module):\n",
    "    # ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "    def __init__(self, block, filters, nbr_blocks):\n",
    "        super(myResNet, self).__init__()\n",
    "        \n",
    "        num_classes = 10\n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "        self.inplanes = filters[0]  # 64\n",
    "        \n",
    "        # self.groups = 1\n",
    "        #self.base_width = 64\n",
    "        # Första filtret för ResNet \"börjar\"\n",
    "        self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # ResNet for NAS\n",
    "        reslays = len(nbr_blocks)\n",
    "        self.reslays = reslays\n",
    "        for idx in range(reslays):\n",
    "            key = 'layer' + str(idx+1)\n",
    "            print('init: ', key)\n",
    "            f = filters[idx + 1] # first was for the 7x7\n",
    "            b = nbr_blocks[idx]\n",
    "                        \n",
    "            if idx == 0:\n",
    "                lay = self._make_layer(block, f, b)\n",
    "            else:\n",
    "                lay = self._make_layer(block, f, b, stride=2)\n",
    "            \n",
    "            setattr(self, key, lay)\n",
    "        \"\"\"    \n",
    "        # ResNet regular    \n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        \"\"\"\n",
    "        # Slutfas\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        out_planes = filters[-1]\n",
    "        self.fc = nn.Linear(out_planes * block.expansion, num_classes)\n",
    "        \n",
    "        # What is this???\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "        # might want to Zero-initialize the last BN in each residual branch here\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = 1\n",
    "        dilate=False\n",
    "        \n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion  # block expansion = 1 for basic block\n",
    "        \n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        # NAS pass\n",
    "        for idx in range(self.reslays):\n",
    "            key = 'layer' + str(idx+1)\n",
    "            #print('fp: ', key)\n",
    "            x = getattr(self, key)(x)\n",
    "            #print(x.shape)\n",
    "        \n",
    "        \"\"\"\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \"\"\"        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        # We do not need softmax since it is done inside nn.CrossEntropyLoss()\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "    \n",
    "# layer_data = [(64,1), (128,1), (254, 1), (512,1)]\n",
    "fil = [64, 64,128,254,512]\n",
    "blk = [1,1,1,1]\n",
    "layer_data = (fil,blk)\n",
    "\n",
    "#myResNet(BasicBlock, layer_data)\n",
    "#print(myResNet(BasicBlock, layer_data))\n",
    "\n",
    "count_params(myResNet(BasicBlock, *layer_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small resnet of deepth  14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "175258"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RNsmall(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(RNsmall, self).__init__()\n",
    "        \n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "        self.inplanes = 16\n",
    "        \n",
    "        # Första filtret för ResNet \"börjar\"\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # ResNet\n",
    "        self.layer1 = self._make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
    "\n",
    "        # Slutfas\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
    "        \n",
    "        # What is this???\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "        # might want to Zero-initialize the last BN in each residual branch here\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = 1\n",
    "        dilate=False\n",
    "        \n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion  # block expansion = 1 for basic block\n",
    "        \n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # The blocks should have identity mapping (method A) for residuals\n",
    "        x = self.layer1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.layer2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.layer3(x)\n",
    "        #print(x.shape)\n",
    "        # x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        # We do not need softmax since it is done inside nn.CrossEntropyLoss()\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "#ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "#print(ResNet(BasicBlock, [1,1,1,1]))\n",
    "n = 2\n",
    "print('small resnet of deepth ', 6*n + 2)\n",
    "count_params(RNsmall(BasicBlock, [n,n,n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "loaded the mnist data\n",
      "input:  torch.Size([128, 3, 32, 32])\n",
      "small resnet of deepth  14\n",
      "params:  175258\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size_train = 128\n",
    "batch_size_test = 1000\n",
    "# learning_rate = 0.1\n",
    "# momentum = 0.5\n",
    "#log_interval = 10\n",
    "size = (32,32)     # ResNet is made for 224, Mnist is 28, Cifar-10 is 32\n",
    "train_loader, test_loader, classes = get_data_loaders(batch_size_train, batch_size_test, size=size)\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print('input: ', example_data.shape)\n",
    "criterion = nn.CrossEntropyLoss()    \n",
    "\n",
    "# Call myResNet\n",
    "# fil = [16, 64,4, 32]\n",
    "# blk = [1,1,1]\n",
    "# layer_data = (fil,blk)\n",
    "# layer_data = [(64,1), (128,1), (254, 1), (512,1)]\n",
    "# network = myResNet(BasicBlock, *layer_data)\n",
    "\n",
    "# Call RNsmall\n",
    "n = 2\n",
    "print('small resnet of deepth ', 6*n + 2)\n",
    "network = RNsmall(BasicBlock, [n,n,n])\n",
    "\n",
    "print('params: ', count_params(network))\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "outputs = network(images)\n",
    "\n",
    "optimizer = optim.Adam(network.parameters())\n",
    "\n",
    "#outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.782\n",
      "[1,   200] loss: 1.431\n",
      "[1,   300] loss: 1.262\n",
      "[2,   100] loss: 1.090\n",
      "[2,   200] loss: 1.028\n",
      "[2,   300] loss: 0.997\n",
      "[3,   100] loss: 0.886\n",
      "[3,   200] loss: 0.864\n",
      "[3,   300] loss: 0.839\n",
      "[4,   100] loss: 0.753\n",
      "[4,   200] loss: 0.743\n",
      "[4,   300] loss: 0.725\n",
      "[5,   100] loss: 0.645\n",
      "[5,   200] loss: 0.655\n",
      "[5,   300] loss: 0.649\n",
      "[6,   100] loss: 0.577\n",
      "[6,   200] loss: 0.589\n",
      "[6,   300] loss: 0.581\n",
      "[7,   100] loss: 0.514\n",
      "[7,   200] loss: 0.521\n",
      "[7,   300] loss: 0.530\n",
      "[8,   100] loss: 0.447\n",
      "[8,   200] loss: 0.474\n",
      "[8,   300] loss: 0.478\n",
      "[9,   100] loss: 0.399\n",
      "[9,   200] loss: 0.414\n",
      "[9,   300] loss: 0.442\n",
      "[10,   100] loss: 0.372\n",
      "[10,   200] loss: 0.370\n",
      "[10,   300] loss: 0.388\n",
      "Finished Training it took  69.23674676543257  minutes to train\n"
     ]
    }
   ],
   "source": [
    "# tog typ en kvart\n",
    "t0 = time.perf_counter()\n",
    "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = network(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 20 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training it took ', (time.perf_counter() - t0)/60, ' minutes to train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 77.600000 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = network(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "   \n",
    "print('Accuracy of the network on the 10000 test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.44"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "98% på 8 min med [1,1,1,1]\n",
    "98.3% på 15 min med |2,2,2,2]\n",
    "99.1% på 11 min (5 eps) med fil = [16, 64,128], blk = [1,1]\n",
    "CIFAR rnsmall [2,2,2]: 56% och 78% efter 1 resp 10 epochs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "loaded the mnist data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  cat  bird  deer horse\n"
     ]
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 5 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "bs = 4\n",
    "tl, _, classes = get_data_loaders(bs, bs, size=(32,32))\n",
    "dataiter = iter(tl)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(bs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
